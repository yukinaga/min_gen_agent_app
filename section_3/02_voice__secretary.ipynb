{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXDjN5YWp3NjKOy2lBJElv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/min_gen_agent_app/blob/main/section_3/02_voice__secretary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 音声でやりとりする秘書アプリ\n",
        "\n",
        "このノートブックでは、音声で話しかけると答えてくれる秘書アプリを体験できます。  \n",
        "OpenAI の Agents SDK を使い、自然な会話を通じてタスク管理や日付確認などを行います。  \n",
        "ブラウザから直接マイクを使って対話できます。"
      ],
      "metadata": {
        "id": "tyqlOlVMyMEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## アプリの仕組み\n",
        "\n",
        "###音声入力\n",
        "\n",
        "マイクで話しかけると、音声データが録音されます。\n",
        "\n",
        "録音した音声は OpenAI の音声認識モデル（gpt-4o-mini-transcribe）でテキストに変換されます。\n",
        "\n",
        "### エージェントが理解・判断\n",
        "\n",
        "テキスト化された内容を Agents SDK のエージェントに渡します。\n",
        "\n",
        "エージェントは質問や命令を理解し、必要に応じて「タスクを追加する」「現在時刻を確認する」などの関数ツールを自動で呼び出します。\n",
        "\n",
        "### 音声で回答\n",
        "\n",
        "エージェントの回答テキストを 音声合成モデル（gpt-4o-mini-tts）が自然な日本語音声に変換します。\n",
        "\n",
        "秘書が話しているように、音声で返答が再生されます。\n",
        "\n",
        "### 使用するAI技術\n",
        "OpenAI Agents SDK:\tAIエージェントを作るためのPython SDK。関数ツールや会話メモリを簡単に扱えます。  \n",
        "Speech-to-Text (STT):\t音声をテキストに変換します。モデルは「gpt-4o-mini-transcribe」  \n",
        "Text-to-Speech (TTS):\tテキストを音声に変換します。モデルは「gpt-4o-mini-tts」"
      ],
      "metadata": {
        "id": "MMS2tVbXyVu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2MqNgT8ktIO"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 🎙️ 音声でやりとりする秘書アプリ\n",
        "# --------------------------------------------\n",
        "# Google Colab 上で動作するデモ\n",
        "# OpenAI Agents SDK を使って、音声で会話できる秘書を作ります。\n",
        "# マイクで話しかけると：\n",
        "#   1) 音声 → テキスト（文字起こし）\n",
        "#   2) エージェントが回答を生成\n",
        "#   3) 回答テキスト → 音声（合成音声で再生）\n",
        "# を行います。\n",
        "#\n",
        "# 使い方：\n",
        "# ① Colab の左サイドバー → 「🔑 Secrets」で\n",
        "#    OPENAI_API_KEY を登録してください。\n",
        "# ② このセルをそのまま実行します。\n",
        "# ============================================\n",
        "\n",
        "# ===== 必要なパッケージのインストール ===============================\n",
        "!pip -q install --upgrade openai-agents openai gradio\n",
        "\n",
        "# ===== インポートと初期設定 =========================================\n",
        "import os, uuid, asyncio, tempfile\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from agents import Agent, Runner, function_tool, SQLiteSession\n",
        "\n",
        "# --- APIキーを Secrets から読み込み ---\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY が見つかりません。左サイドバーの 🔑 Secrets で登録してください。\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# OpenAI クライアントを初期化（環境変数を自動参照）\n",
        "client = OpenAI()\n",
        "\n",
        "# ===== 音声変換ユーティリティ ======================================\n",
        "async def speech_to_text(audio_path: str) -> str:\n",
        "    \"\"\"音声ファイルをテキストに変換（Speech-to-Text）\"\"\"\n",
        "    with open(audio_path, \"rb\") as f:\n",
        "        tr = client.audio.transcriptions.create(\n",
        "            model=\"gpt-4o-mini-transcribe\",  # 高速で高精度な文字起こしモデル\n",
        "            file=f,\n",
        "        )\n",
        "    return (tr.text or \"\").strip()\n",
        "\n",
        "async def text_to_speech(text: str, voice: str = \"alloy\") -> str:\n",
        "    \"\"\"テキストを音声に変換（Text-to-Speech）\"\"\"\n",
        "    out_path = os.path.join(tempfile.gettempdir(), f\"reply_{uuid.uuid4().hex}.mp3\")\n",
        "    # 音声ファイルをストリーミングで保存（長文でも安全）\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=\"gpt-4o-mini-tts\",\n",
        "        voice=voice,\n",
        "        input=text,\n",
        "    ) as resp:\n",
        "        resp.stream_to_file(out_path)\n",
        "    return out_path\n",
        "\n",
        "# ===== エージェントが使う関数ツール =================================\n",
        "# この部分は「秘書が呼び出せる機能」を定義します。\n",
        "TODO = []\n",
        "\n",
        "@function_tool\n",
        "def add_todo(task: str) -> str:\n",
        "    \"\"\"タスクを追加します。\"\"\"\n",
        "    if not task.strip():\n",
        "        return \"空のタスクは追加できません。\"\n",
        "    TODO.append(task.strip())\n",
        "    return f\"タスクを追加: {task}（合計 {len(TODO)} 件）\"\n",
        "\n",
        "@function_tool\n",
        "def list_todo() -> list[str]:\n",
        "    \"\"\"現在のタスク一覧を返します。\"\"\"\n",
        "    return TODO\n",
        "\n",
        "@function_tool\n",
        "def clear_todo() -> str:\n",
        "    \"\"\"タスクをすべて削除します。\"\"\"\n",
        "    TODO.clear()\n",
        "    return \"タスクをすべて削除しました。\"\n",
        "\n",
        "@function_tool\n",
        "def now() -> str:\n",
        "    \"\"\"現在の日時（日本時間）を返します。\"\"\"\n",
        "    from datetime import datetime, timezone, timedelta\n",
        "    JST = timezone(timedelta(hours=9), name=\"JST\")\n",
        "    return datetime.now(JST).strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "# ===== 秘書エージェントの設定 ======================================\n",
        "secretary = Agent(\n",
        "    name=\"Voice Secretary\",\n",
        "    instructions=(\n",
        "        \"あなたは音声でやりとりする日本語の秘書です。\"\n",
        "        \"丁寧でわかりやすく、1〜3文で簡潔に答えてください。\"\n",
        "        \"最後に『次のアクション』を1つ提案します。\"\n",
        "        \"必要に応じて add_todo / list_todo / clear_todo / now を使ってください。\"\n",
        "    ),\n",
        "    tools=[add_todo, list_todo, clear_todo, now],\n",
        ")\n",
        "\n",
        "# 会話の記憶を保持する軽量セッション\n",
        "session = SQLiteSession(\"gradio_voice_secretary\")\n",
        "\n",
        "# ===== Gradio の処理関数 ============================================\n",
        "GREETING = \"こんにちは。秘書のエコです。ご用件をどうぞ。\"\n",
        "\n",
        "async def handle_interaction(audio_file, text_input, voice, messages):\n",
        "    \"\"\"音声またはテキスト入力を受け取り、エージェントの返答と音声を返す\"\"\"\n",
        "    messages = messages or []\n",
        "\n",
        "    # 1) 音声またはテキストを取得\n",
        "    if audio_file:\n",
        "        try:\n",
        "            user_text = await speech_to_text(audio_file)\n",
        "        except Exception as e:\n",
        "            user_text = \"\"\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"文字起こしエラー: {e}\"})\n",
        "    else:\n",
        "        user_text = (text_input or \"\").strip()\n",
        "\n",
        "    if not user_text:\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"音声またはテキストで話しかけてください。\"})\n",
        "        return messages, None\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
        "\n",
        "    # 2) エージェントに質問\n",
        "    try:\n",
        "        result = await Runner.run(secretary, input=user_text, session=session)\n",
        "        bot_text = (result.final_output or \"\").strip()\n",
        "    except Exception as e:\n",
        "        bot_text = f\"回答生成でエラーが発生しました: {e}\"\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": bot_text})\n",
        "\n",
        "    # 3) テキストを音声に変換\n",
        "    tts_path = None\n",
        "    try:\n",
        "        tts_path = await text_to_speech(bot_text, voice=voice)\n",
        "    except Exception as e:\n",
        "        messages.append({\"role\": \"assistant\", \"content\": f\"音声合成に失敗しました: {e}\"})\n",
        "\n",
        "    return messages, tts_path\n",
        "\n",
        "async def clear_all():\n",
        "    \"\"\"チャットとタスクを初期化\"\"\"\n",
        "    TODO.clear()\n",
        "    try:\n",
        "        await session.clear_session()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return [{\"role\": \"assistant\", \"content\": GREETING}], None\n",
        "\n",
        "# ===== Gradio UI の構築 =============================================\n",
        "with gr.Blocks(title=\"音声秘書アプリ\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"## 🎧 音声でやりとりする秘書アプリ\\n\"\n",
        "        \"- マイクで話しかけると、秘書がテキストと音声で返答します。\\n\"\n",
        "        \"- 例：「現在の日時を教えて」「タスクを一覧して」など。\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        audio_in = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"🎤 マイク入力\")\n",
        "        text_in = gr.Textbox(label=\"⌨️ テキスト入力（音声が使えないとき）\",\n",
        "                             placeholder=\"例）明日の午前中にA社に電話するタスクを追加して\")\n",
        "\n",
        "    with gr.Row():\n",
        "        voice = gr.Dropdown(\n",
        "            label=\"音声の種類（TTS Voice）\",\n",
        "            choices=[\"alloy\", \"shimmer\", \"nova\", \"onyx\", \"echo\", \"fable\"],\n",
        "            value=\"alloy\"\n",
        "        )\n",
        "        send_btn = gr.Button(\"▶️ 送信\", variant=\"primary\")\n",
        "        clear_btn = gr.Button(\"🧹 クリア\")\n",
        "\n",
        "    chat = gr.Chatbot(\n",
        "        label=\"会話\",\n",
        "        type=\"messages\",  # 推奨形式（警告回避）\n",
        "        value=[{\"role\": \"assistant\", \"content\": GREETING}],\n",
        "        height=360,\n",
        "    )\n",
        "    audio_out = gr.Audio(label=\"🔊 音声回答\", autoplay=True)\n",
        "\n",
        "    state = gr.State([{\"role\": \"assistant\", \"content\": GREETING}])\n",
        "\n",
        "    # イベント設定\n",
        "    send_btn.click(\n",
        "        fn=handle_interaction,\n",
        "        inputs=[audio_in, text_in, voice, state],\n",
        "        outputs=[chat, audio_out]\n",
        "    ).then(fn=lambda h, *_: h, inputs=[chat], outputs=[state])\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_all,\n",
        "        inputs=[],\n",
        "        outputs=[chat, audio_out]\n",
        "    ).then(fn=lambda h, *_: h, inputs=[chat], outputs=[state])\n",
        "\n",
        "# ===== アプリの起動 =================================================\n",
        "demo.launch()\n"
      ]
    }
  ]
}